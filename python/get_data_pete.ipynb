{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_main = 'https://www.idealista.com/'\n",
    "url_main_list = 'https://www.idealista.com/venta-viviendas/madrid-madrid/con-pisos/'\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1\n",
    "\n",
    "for n in range(1, 2):\n",
    "    url = url_main_list + 'pagina-' + str(n) + '.htm'\n",
    "    print(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "#r = requests.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Accept-Encoding': 'gzip, deflate, br',\n",
    "          'Accept-Language': 'en-US,en;q=0.9,es-ES;q=0.8,es;q=0.7',\n",
    "          'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "          'Cache-Control': 'no-cache'}\n",
    "\n",
    "html = requests.get('https://www.idealista.com/venta-viviendas/madrid-madrid/con-pisos/', headers = headers).content\n",
    "soup1 = BeautifulSoup(html)\n",
    "print(soup1.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html1 = requests.get(url1).content\n",
    "soup1 = BeautifulSoup(html1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from itertools import cycle\n",
    "\n",
    "class idealSpider:\n",
    "\n",
    "    def __init__(self, url_pattern, range_to_scrape=10, content_parser=None, headers=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.range_to_scrape = range_to_scrape\n",
    "        self.content_parser = content_parser\n",
    "        self.headers = headers\n",
    "        self.result = []\n",
    "        \n",
    "    '''\n",
    "        def get_random_ua():\n",
    "            random_ua = ''\n",
    "            ua_file = 'ua_file.txt'\n",
    "            try:\n",
    "                with open(ua_file) as f:\n",
    "                    lines = f.readlines()\n",
    "                if len(lines) > 0:\n",
    "                    prng = np.random.RandomState()\n",
    "                    index = prng.permutation(len(lines) - 1)\n",
    "                    idx = np.asarray(index, dtype=np.integer)[0]\n",
    "                    random_proxy = lines[int(idx)]\n",
    "            except Exception as ex:\n",
    "                print('Exception in random_ua')\n",
    "                print(str(ex))\n",
    "            finally:\n",
    "                return random_ua\n",
    "\n",
    "    '''\n",
    "\n",
    "    def ua_random(self):\n",
    "        random_ua = ''\n",
    "        ua_file = 'agents.txt'\n",
    "        try:\n",
    "            with open(ua_file) as f:\n",
    "                lines = f.readlines()\n",
    "            if len(lines) > 0:\n",
    "                random_ua = random.choice(lines)\n",
    "                random_ua = random_ua.split('\\n')\n",
    "        except Exception as ex:\n",
    "            print('Exception in ua_random')\n",
    "            print(str(ex))\n",
    "        finally:\n",
    "            return random_ua[0] \n",
    "        \n",
    "    def scrape_url(self, url, proxy):\n",
    "        user_agent = self.ua_random()\n",
    "        print(user_agent)\n",
    "        proxy = 'http://'+ proxy\n",
    "        #print(proxy)\n",
    "        headers = self.headers\n",
    "        headers['user-agent'] = user_agent\n",
    "\n",
    "        try:\n",
    "            #response = requests.get(url, headers = headers, proxies={\"http\": proxy, \"https\": proxy})\n",
    "            response = requests.get(url, headers = headers, proxies = {\"https\": proxy})\n",
    "            print(response.status_code)\n",
    "            response.raise_for_status()\n",
    "            contenido = response.content\n",
    "            links = self.content_parser(contenido)\n",
    "            if len(links) >  0:\n",
    "                for link in links:\n",
    "                    self.result.append(link)\n",
    "            else:\n",
    "                self.result.append(url)\n",
    "            result = links   \n",
    "        except requests.exceptions.HTTPError as e_http:\n",
    "            result = \"Error http:\" + str(e_http)\n",
    "        except requests.exceptions.ConnectionError as e_conect:\n",
    "            result = \"Error de conexión:\" + str(e_conect)\n",
    "        except requests.exceptions.SSLError as e_ssl:\n",
    "            result = \"Error de SSL: \" + str(e_ssl)\n",
    "        except requests.exceptions.Timeout as e_time:\n",
    "            result = \"Error timeout:\" + str(e_time)\n",
    "        except requests.exceptions.TooManyRedirects as e_redi:\n",
    "            result = \"Error demasiadas redirecciones:\" + str(e_redi)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            result = \"Error Desconocido: \" + str(e)\n",
    "        \n",
    "        self.output_results(result)\n",
    "        \n",
    "    \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    def get_proxies(self):\n",
    "        proxie_file = 'proxies.txt'\n",
    "        try:\n",
    "            with open(proxie_file) as f:\n",
    "                proxies = f.readlines()\n",
    "            return proxies\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def get_proxies2(self):\n",
    "        url = 'https://free-proxy-list.net/'\n",
    "        response = requests.get(url)\n",
    "        parser = fromstring(response.text)\n",
    "        proxies = set()\n",
    "        for i in parser.xpath('//tbody/tr')[:10]:\n",
    "            if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
    "                #Grabbing IP and corresponding PORT\n",
    "                proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "                proxies.add(proxy)\n",
    "        return proxies\n",
    "\n",
    "    def kickstart(self):\n",
    "        proxies = self.get_proxies2()\n",
    "        proxy_pool = cycle(proxies)\n",
    "        for i in self.range_to_scrape:\n",
    "            proxy = next(proxy_pool)\n",
    "            self.scrape_url(self.url_pattern % i, proxy)\n",
    "            time.sleep(random.randint(2, 5))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 5.1; rv:43.0) Gecko/20100101 Firefox/43.0\n",
      "\n",
      "['Mozilla/5.0 (Windows NT 5.1; rv:43.0) Gecko/20100101 Firefox/43.0', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mozilla/5.0 (Windows NT 5.1; rv:43.0) Gecko/20100101 Firefox/43.0'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def testagent():\n",
    "    random_ua = ''\n",
    "    ua_file = 'agents.txt'\n",
    "    try:\n",
    "        with open(ua_file) as f:\n",
    "            lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            random_ua = random.choice(lines)\n",
    "            print(random_ua)\n",
    "            random_ua = random_ua.split('\\n')\n",
    "            print(random_ua)\n",
    "    except Exception as ex:\n",
    "        print('Exception in ua_random')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return random_ua[0]\n",
    "    \n",
    "testagent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_general = 'https://www.idealista.com/venta-viviendas/madrid-madrid/con-pisos/pagina-%s.htm'\n",
    "range_to_scrape = range(1, 50)\n",
    "sleep = 3\n",
    "headers = {'Accept-Encoding': 'gzip, deflate, br',\n",
    "          'Accept-Language': 'en-US,en;q=0.9,es-ES;q=0.8,es;q=0.7',\n",
    "          'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "          'Cache-Control': 'max-age=0',\n",
    "          'Upgrade-Insecure-Requests': '1'}\n",
    "\n",
    "def quotes_parser_refs(content):\n",
    "    soup1 = BeautifulSoup(content)\n",
    "    print(soup1.prettify())\n",
    "    links = soup1.find_all('a', 'item-link')\n",
    "    hrefs = []\n",
    "    for a in links:\n",
    "        hrefs.append(a['href'])\n",
    "    return hrefs\n",
    "    \n",
    "spider = idealSpider(URL_general, range_to_scrape, content_parser = quotes_parser_refs, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 6.1; rv:47.0) Gecko/20100101 Firefox/47.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-9eb77c67b238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-185-93aac921e5d6>\u001b[0m in \u001b[0;36mkickstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange_to_scrape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrape_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_pattern\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-185-93aac921e5d6>\u001b[0m in \u001b[0;36mscrape_url\u001b[0;34m(self, url, proxy)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m#response = requests.get(url, headers = headers, proxies={\"http\": proxy, \"https\": proxy})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"https\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0mis_new_proxy_conn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_new_proxy_conn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_prepare_proxy\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[1;32m    804\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proxy_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# Calls self._set_hostport(), so self.host is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;31m# self._tunnel_host below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;31m# Mark this connection as not reusable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spider.kickstart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import fromstring\n",
    "def get_proxies():\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    response = requests.get(url)\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:10]:\n",
    "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
    "            #Grabbing IP and corresponding PORT\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies\n",
    "proxies = get_proxies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies2 = get_proxies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103.88.234.58:34515',\n",
       " '117.74.113.45:34155',\n",
       " '164.77.175.246:30957',\n",
       " '168.228.51.197:59144',\n",
       " '176.192.8.6:60630',\n",
       " '197.254.4.130:44187',\n",
       " '35.245.217.59:3128',\n",
       " '5.58.149.229:46759',\n",
       " '80.188.212.2:44577',\n",
       " '93.77.121.45:54799'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import fromstring\n",
    "import requests\n",
    "from itertools import cycle\n",
    "import traceback\n",
    "\n",
    "def get_proxies():\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    response = requests.get(url)\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:10]:\n",
    "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies\n",
    "\n",
    "\n",
    "#If you are copy pasting proxy ips, put in the list below\n",
    "#proxies = ['121.129.127.209:80', '124.41.215.238:45169', '185.93.3.123:8080', '194.182.64.67:3128', '106.0.38.174:8080', '163.172.175.210:3128', '13.92.196.150:8080']\n",
    "proxies = get_proxies()\n",
    "proxy_pool = cycle(proxies)\n",
    "\n",
    "url = 'https://httpbin.org/ip'\n",
    "for i in range(1,11):\n",
    "    #Get a proxy from the pool\n",
    "    proxy = next(proxy_pool)\n",
    "    print(\"Request #%d\"%i)\n",
    "    try:\n",
    "        response = requests.get(url,proxies={\"http\": proxy, \"https\": proxy})\n",
    "        print(response.json())\n",
    "    except:\n",
    "        #Most free proxies will often get connection errors. You will have retry the entire request using another proxy to work. \n",
    "        #We will just skip retries as its beyond the scope of this tutorial and we are only downloading a single url \n",
    "        print(\"Skipping. Connnection error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxies():\n",
    "    proxie_file = 'proxies.txt'\n",
    "    try:\n",
    "        with open(proxie_file) as f:\n",
    "            proxies = f.readlines()\n",
    "        return proxies\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = get_proxies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "print(randint(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103.88.234.58:34515',\n",
       " '109.101.139.106:32341',\n",
       " '176.192.8.6:60630',\n",
       " '213.21.18.18:57362',\n",
       " '5.58.149.229:46759',\n",
       " '78.41.174.197:57649',\n",
       " '80.188.212.2:44577',\n",
       " '93.77.121.45:54799'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://103.88.234.58:34515\\n'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy = 'http://'+proxies[0]\n",
    "proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"es\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <title>\n",
      "   idealista.com : pisos madrid, pisos barcelona, pisos valencia. inmobiliarias venta, alquiler y obra nueva\n",
      "  </title>\n",
      "  <link href=\"https://fonts.googleapis.com/css?family=Open+Sans:300\" rel=\"stylesheet\"/>\n",
      "  <style>\n",
      "   html, body{margin: 0; padding: 0; font-family: 'Open Sans', sans-serif; color: #000;}a{color: #c5c5c5; text-decoration: none;}.container{align-items: center; display: flex; flex: 1; justify-content: space-between; flex-direction: column; height: 100%;}.container>div{width: 100%; display: flex; justify-content: center;}.container>div>div{display: flex; width: 80%;}.customer-logo-wrapper{padding-top: 2rem; flex-grow: 0; background-color: #fff; visibility: visible;}.customer-logo{border-bottom: 1px solid #000;}.customer-logo>img{padding-bottom: 1rem; max-height: 50px; max-width: auto;}.page-title-wrapper{flex-grow: 2;}.page-title{flex-direction: column-reverse;}.content-wrapper{flex-grow: 5;}.content{flex-direction: column;}.page-footer-wrapper{align-items: center; flex-grow: 0.2; background-color: #000; color: #c5c5c5; font-size: 70%;}@media (min-width:768px){html, body{height: 100%;}}\n",
      "  </style>\n",
      "  <script async=\"\" defer=\"\" src=\"https://www.google.com/recaptcha/api.js\">\n",
      "  </script>\n",
      " </head>\n",
      " <body>\n",
      "  <section class=\"container\">\n",
      "   <div class=\"customer-logo-wrapper\">\n",
      "    <div class=\"customer-logo\">\n",
      "     <img alt=\"Logo\" src=\"https://st1.idealista.com/static/common/img/icons/logo4.png\"/>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"page-title-wrapper\">\n",
      "    <div class=\"page-title\">\n",
      "     <h1>\n",
      "     </h1>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"content-wrapper\">\n",
      "    <div class=\"content\">\n",
      "     <p>\n",
      "      Vaya! parece que estamos recibiendo muchas peticiones tuyas en poco tiempo\n",
      "      <br/>\n",
      "      Para ver que realmente eres tú y no un maligno robot, te pedimos que hagas la siguiente validación:\n",
      "     </p>\n",
      "     <div id=\"px-captcha\">\n",
      "     </div>\n",
      "     <p>\n",
      "      Un saludo,\n",
      "      <br/>\n",
      "      El equipo de idealista\n",
      "     </p>\n",
      "     <p>\n",
      "      Reference ID: #c9c79ba0-83d7-11e9-869b-71fcc58920ad\n",
      "     </p>\n",
      "     <p>\n",
      "      ¿No consigues pasar de aquí?\n",
      "      <br/>\n",
      "      Atención personalizada\n",
      "      <strong>\n",
      "       902 55 98 58\n",
      "      </strong>\n",
      "      <br/>\n",
      "      Coste de una llamada provincial\n",
      "      <br/>\n",
      "      Lunes a Viernes de 9:00 a 21:00\n",
      "     </p>\n",
      "     <p id=\"copyright\">\n",
      "      Copyright © 2000-\n",
      "      <span id=\"year\">\n",
      "      </span>\n",
      "      idealista\n",
      "     </p>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"page-footer-wrapper\">\n",
      "    <div class=\"page-footer\">\n",
      "     <p>\n",
      "      Powered by\n",
      "      <a href=\"https://www.perimeterx.com\">\n",
      "       PerimeterX\n",
      "      </a>\n",
      "      , Inc.\n",
      "     </p>\n",
      "    </div>\n",
      "   </div>\n",
      "  </section>\n",
      "  <script>\n",
      "   window._pxAppId='PXm4C135aU'; window._pxJsClientSrc='/m4C135aU/init.js'; window._pxFirstPartyEnabled= false ; window._pxVid=''; window._pxUuid='c9c79ba0-83d7-11e9-869b-71fcc58920ad'; window._pxHostUrl='/m4C135aU/xhr'; window._pxreCaptchaTheme='dark';\n",
      "  </script>\n",
      "  <script>\n",
      "   var s=document.createElement('script'); s.src='/m4C135aU/captcha/captcha.js?a=c&u=c9c79ba0-83d7-11e9-869b-71fcc58920ad&v=&m=0'; var p=document.getElementsByTagName('head')[0]; p.insertBefore(s, null); if ( false ){s.onerror=function(){s=document.createElement('script'); var suffixIndex='/m4C135aU/captcha/captcha.js?a=c&u=c9c79ba0-83d7-11e9-869b-71fcc58920ad&v=&m=0'.indexOf('/captcha.js'); var temperedBlockScript='/m4C135aU/captcha/captcha.js?a=c&u=c9c79ba0-83d7-11e9-869b-71fcc58920ad&v=&m=0'.substring(suffixIndex); s.src='//captcha.px-cdn.net/PXm4C135aU' + temperedBlockScript; p.parentNode.insertBefore(s, p);};}\n",
      "  </script>\n",
      "  <script>\n",
      "   document.getElementById(\"year\").innerHTML=new Date().getFullYear();\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "test_proxy = '58.123.205.81:80'\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36'\n",
    "\n",
    "headers = {'user_agent' : user_agent,\n",
    "           'Accept-Encoding': 'gzip, deflate, br',\n",
    "          'Accept-Language': 'en-US,en;q=0.9,es-ES;q=0.8,es;q=0.7',\n",
    "          'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "          'Cache-Control': 'no-cache'}\n",
    "\n",
    "html = requests.get('https://www.idealista.com/venta-viviendas/madrid-madrid/con-pisos/pagina-3.htm', headers = headers, proxies = {'https': test_proxy}).content\n",
    "soup1 = BeautifulSoup(html)\n",
    "print(soup1.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request #1\n",
      "Skipping. Connnection error\n",
      "Request #2\n",
      "Skipping. Connnection error\n",
      "Request #3\n",
      "{'origin': '58.123.205.81, 58.123.205.81'}\n",
      "Request #4\n",
      "Skipping. Connnection error\n",
      "Request #5\n",
      "{'origin': '128.199.252.137, 128.199.252.137'}\n",
      "Request #6\n",
      "Skipping. Connnection error\n",
      "Request #7\n",
      "Skipping. Connnection error\n",
      "Request #8\n",
      "{'origin': '58.123.205.81, 58.123.205.81'}\n",
      "Request #9\n",
      "Skipping. Connnection error\n",
      "Request #10\n",
      "{'origin': '128.199.252.137, 128.199.252.137'}\n"
     ]
    }
   ],
   "source": [
    "from lxml.html import fromstring\n",
    "import requests\n",
    "from itertools import cycle\n",
    "import traceback\n",
    "\n",
    "def get_proxies():\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    response = requests.get(url)\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:10]:\n",
    "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies\n",
    "\n",
    "\n",
    "#If you are copy pasting proxy ips, put in the list below\n",
    "#proxies = ['121.129.127.209:80', '124.41.215.238:45169', '185.93.3.123:8080', '194.182.64.67:3128', '106.0.38.174:8080', '163.172.175.210:3128', '13.92.196.150:8080']\n",
    "proxies = get_proxies()\n",
    "proxy_pool = cycle(proxies)\n",
    "\n",
    "url = 'https://httpbin.org/ip'\n",
    "for i in range(1,11):\n",
    "    #Get a proxy from the pool\n",
    "    proxy = next(proxy_pool)\n",
    "    print(\"Request #%d\"%i)\n",
    "    try:\n",
    "        response = requests.get(url,proxies={\"http\": proxy, \"https\": proxy})\n",
    "        print(response.json())\n",
    "    except:\n",
    "        #Most free proxies will often get connection errors. You will have retry the entire request using another proxy to work. \n",
    "        #We will just skip retries as its beyond the scope of this tutorial and we are only downloading a single url \n",
    "        print(\"Skipping. Connnection error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
